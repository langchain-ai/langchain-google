{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph Agent Analytics with BigQuery\n",
    "\n",
    "This notebook demonstrates how **BigQuery serves as a unified platform** for LangGraph Agent:\n",
    "- **Observability** - Real-time event monitoring and tracing\n",
    "- **Analytics** - Tool usage, latency analysis, and cost tracking\n",
    "- **Evaluation** - Quality assessment and safety monitoring\n",
    "- **Memory** - Semantic search across agent conversations\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  LangGraph      â”‚â”€â”€â”€â”€â–¶â”‚  BigQueryCallbackHandler â”‚â”€â”€â”€â”€â–¶â”‚    BigQuery     â”‚\n",
    "â”‚  Agent          â”‚     â”‚  (Async Logging)         â”‚     â”‚  agent_events   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                                                  â”‚\n",
    "                                                                  â–¼\n",
    "                                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                                                         â”‚  Analytics &    â”‚\n",
    "                                                         â”‚  Dashboards     â”‚\n",
    "                                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install google-cloud-bigquery pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication for Google Colab\n",
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    print(\"Authenticated with Google Colab\")\n",
    "except ImportError:\n",
    "    print(\"Not running in Colab - using application default credentials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configuration - UPDATE THESE FOR YOUR ENVIRONMENT\n",
    "PROJECT_ID = \"test-project-0728-467323\"  # Your GCP project\n",
    "DATASET_ID = \"agent_analytics\"           # Your BigQuery dataset\n",
    "TABLE_ID = \"agent_events_v2\"             # Your events table\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "print(f\"Connected to BigQuery: {PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to run queries\n",
    "def run_query(sql: str) -> pd.DataFrame:\n",
    "    \"\"\"Execute a BigQuery SQL query and return results as a DataFrame.\"\"\"\n",
    "    return client.query(sql).to_dataframe()\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Table Schema\n\nThe `agent_events_v2` table captures all LangGraph agent events with the following schema:\n\n| Column | Type | Description |\n|--------|------|-------------|\n| `timestamp` | TIMESTAMP | Event timestamp |\n| `event_type` | STRING | LLM_REQUEST, LLM_RESPONSE, TOOL_STARTING, TOOL_COMPLETED, NODE_STARTING, GRAPH_START, GRAPH_END, etc. |\n| `agent` | STRING | Agent name (e.g., finance_assistant, travel_planner) |\n| `session_id` | STRING | Session identifier for conversation tracking |\n| `user_id` | STRING | User identifier |\n| `trace_id` | STRING | Distributed trace ID |\n| `span_id` | STRING | Span ID within trace |\n| `content` | JSON | Event content (prompts, responses, tool args/results) |\n| `attributes` | JSON | Additional attributes (tool_name, langgraph metadata) |\n| `latency_ms` | JSON | Latency measurements |\n| `status` | STRING | OK, ERROR |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 1: Real-time Observability\n",
    "\n",
    "Monitor agent activity in real-time, track events, and understand the flow of requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Recent Event Stream\n",
    "\n",
    "View the most recent agent events across all agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_events_sql = f\"\"\"\n",
    "SELECT \n",
    "    timestamp,\n",
    "    agent,\n",
    "    event_type,\n",
    "    session_id,\n",
    "    user_id,\n",
    "    JSON_EXTRACT_SCALAR(attributes, '$.tool_name') as tool_name,\n",
    "    CAST(JSON_EXTRACT_SCALAR(latency_ms, '$.total_ms') AS INT64) as latency_ms,\n",
    "    status\n",
    "FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`\n",
    "WHERE DATE(timestamp) = CURRENT_DATE()\n",
    "ORDER BY timestamp DESC\n",
    "LIMIT 30\n",
    "\"\"\"\n",
    "\n",
    "recent_events = run_query(recent_events_sql)\n",
    "print(f\"Recent {len(recent_events)} events:\")\n",
    "recent_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Event Volume by Type\n",
    "\n",
    "Understand the distribution of event types across your agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "event_distribution_sql = f\"\"\"\nSELECT \n    event_type,\n    COUNT(*) as count,\n    COUNT(DISTINCT session_id) as unique_sessions\nFROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`\nWHERE DATE(timestamp) = CURRENT_DATE()\nGROUP BY event_type\nORDER BY count DESC\n\"\"\"\n\nevent_dist = run_query(event_distribution_sql)\n\n# Visualization\nif len(event_dist) > 0:\n    fig, ax = plt.subplots(figsize=(10, 6))\n    colors = sns.color_palette(\"husl\", len(event_dist))\n    bars = ax.barh(event_dist['event_type'], event_dist['count'], color=colors)\n    ax.set_xlabel('Event Count')\n    ax.set_title('Event Type Distribution')\n    ax.bar_label(bars, padding=3)\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"No event distribution data found for today.\")\n\nevent_dist"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Agent Activity Summary\n",
    "\n",
    "Compare activity levels across different agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_activity_sql = f\"\"\"\n",
    "SELECT \n",
    "    agent,\n",
    "    COUNT(*) as total_events,\n",
    "    COUNT(DISTINCT session_id) as sessions,\n",
    "    COUNT(DISTINCT user_id) as unique_users,\n",
    "    COUNTIF(event_type = 'LLM_REQUEST') as llm_calls,\n",
    "    COUNTIF(event_type = 'TOOL_STARTING') as tool_calls,\n",
    "    COUNTIF(status = 'ERROR') as errors\n",
    "FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`\n",
    "WHERE DATE(timestamp) = CURRENT_DATE()\n",
    "  AND agent IS NOT NULL\n",
    "GROUP BY agent\n",
    "ORDER BY total_events DESC\n",
    "\"\"\"\n",
    "\n",
    "agent_activity = run_query(agent_activity_sql)\n",
    "agent_activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 2: Performance Analytics\n",
    "\n",
    "Analyze latency, tool usage patterns, and identify performance bottlenecks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tool Usage Analysis\n",
    "\n",
    "Which tools are being used most frequently and by which agents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "tool_usage_sql = f\"\"\"\nSELECT \n    agent,\n    JSON_EXTRACT_SCALAR(attributes, '$.tool_name') as tool_name,\n    COUNT(*) as call_count,\n    AVG(CAST(JSON_EXTRACT_SCALAR(latency_ms, '$.total_ms') AS FLOAT64)) as avg_latency_ms,\n    MAX(CAST(JSON_EXTRACT_SCALAR(latency_ms, '$.total_ms') AS FLOAT64)) as max_latency_ms,\n    COUNTIF(status = 'ERROR') as error_count\nFROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`\nWHERE event_type = 'TOOL_COMPLETED'\n  AND DATE(timestamp) = CURRENT_DATE()\n  AND JSON_EXTRACT_SCALAR(attributes, '$.tool_name') IS NOT NULL\nGROUP BY agent, tool_name\nORDER BY call_count DESC\n\"\"\"\n\ntool_usage = run_query(tool_usage_sql)\n\n# Visualization - Tool usage heatmap\nif len(tool_usage) > 0 and tool_usage['agent'].notna().any() and tool_usage['tool_name'].notna().any():\n    pivot_data = tool_usage.pivot_table(\n        index='tool_name', \n        columns='agent', \n        values='call_count', \n        fill_value=0\n    )\n    \n    # Only create heatmap if pivot_data has data\n    if pivot_data.size > 0 and not pivot_data.empty:\n        fig, ax = plt.subplots(figsize=(12, 6))\n        sns.heatmap(pivot_data, annot=True, fmt='g', cmap='YlOrRd', ax=ax)\n        ax.set_title('Tool Usage by Agent')\n        plt.tight_layout()\n        plt.show()\n    else:\n        print(\"No tool usage data available for heatmap visualization.\")\nelse:\n    print(\"No tool usage data found for today.\")\n\ntool_usage"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Latency Analysis\n",
    "\n",
    "Understand latency distribution across LLM calls and tool executions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "latency_analysis_sql = f\"\"\"\nSELECT \n    event_type,\n    agent,\n    COUNT(*) as count,\n    ROUND(AVG(CAST(JSON_EXTRACT_SCALAR(latency_ms, '$.total_ms') AS FLOAT64)), 2) as avg_latency_ms,\n    ROUND(APPROX_QUANTILES(CAST(JSON_EXTRACT_SCALAR(latency_ms, '$.total_ms') AS FLOAT64), 100)[OFFSET(50)], 2) as p50_latency_ms,\n    ROUND(APPROX_QUANTILES(CAST(JSON_EXTRACT_SCALAR(latency_ms, '$.total_ms') AS FLOAT64), 100)[OFFSET(95)], 2) as p95_latency_ms,\n    MAX(CAST(JSON_EXTRACT_SCALAR(latency_ms, '$.total_ms') AS INT64)) as max_latency_ms\nFROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`\nWHERE DATE(timestamp) = CURRENT_DATE()\n  AND event_type IN ('LLM_RESPONSE', 'TOOL_COMPLETED', 'GRAPH_END')\n  AND JSON_EXTRACT_SCALAR(latency_ms, '$.total_ms') IS NOT NULL\nGROUP BY event_type, agent\nORDER BY avg_latency_ms DESC\n\"\"\"\n\nlatency_analysis = run_query(latency_analysis_sql)\nlatency_analysis"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Graph Execution Analysis\n",
    "\n",
    "Analyze complete graph executions (session-level metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_execution_sql = f\"\"\"\n",
    "WITH graph_sessions AS (\n",
    "    SELECT \n",
    "        session_id,\n",
    "        agent,\n",
    "        user_id,\n",
    "        MIN(timestamp) as start_time,\n",
    "        MAX(timestamp) as end_time,\n",
    "        COUNTIF(event_type = 'LLM_REQUEST') as llm_calls,\n",
    "        COUNTIF(event_type = 'TOOL_STARTING') as tool_calls,\n",
    "        MAX(CASE WHEN event_type = 'GRAPH_END' \n",
    "            THEN CAST(JSON_EXTRACT_SCALAR(latency_ms, '$.total_ms') AS INT64) END) as total_latency_ms,\n",
    "        COUNTIF(status = 'ERROR') as errors\n",
    "    FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`\n",
    "    WHERE DATE(timestamp) = CURRENT_DATE()\n",
    "    GROUP BY session_id, agent, user_id\n",
    ")\n",
    "SELECT \n",
    "    session_id,\n",
    "    agent,\n",
    "    user_id,\n",
    "    start_time,\n",
    "    llm_calls,\n",
    "    tool_calls,\n",
    "    total_latency_ms,\n",
    "    errors,\n",
    "    CASE WHEN errors > 0 THEN 'Failed' ELSE 'Success' END as status\n",
    "FROM graph_sessions\n",
    "ORDER BY start_time DESC\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "graph_execution = run_query(graph_execution_sql)\n",
    "graph_execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Cost Estimation\n",
    "\n",
    "Estimate costs based on token usage (using approximate token counts from content length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_estimation_sql = f\"\"\"\n",
    "WITH token_estimates AS (\n",
    "    SELECT \n",
    "        agent,\n",
    "        event_type,\n",
    "        -- Rough estimate: 1 token â‰ˆ 4 characters\n",
    "        CEIL(LENGTH(TO_JSON_STRING(content)) / 4) as estimated_tokens\n",
    "    FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`\n",
    "    WHERE DATE(timestamp) = CURRENT_DATE()\n",
    "      AND event_type IN ('LLM_REQUEST', 'LLM_RESPONSE')\n",
    ")\n",
    "SELECT \n",
    "    agent,\n",
    "    SUM(CASE WHEN event_type = 'LLM_REQUEST' THEN estimated_tokens ELSE 0 END) as input_tokens,\n",
    "    SUM(CASE WHEN event_type = 'LLM_RESPONSE' THEN estimated_tokens ELSE 0 END) as output_tokens,\n",
    "    SUM(estimated_tokens) as total_tokens,\n",
    "    -- Gemini 1.5 Flash pricing (approximate): $0.075/1M input, $0.30/1M output\n",
    "    ROUND(SUM(CASE WHEN event_type = 'LLM_REQUEST' THEN estimated_tokens ELSE 0 END) * 0.000000075 +\n",
    "          SUM(CASE WHEN event_type = 'LLM_RESPONSE' THEN estimated_tokens ELSE 0 END) * 0.0000003, 4) as estimated_cost_usd\n",
    "FROM token_estimates\n",
    "GROUP BY agent\n",
    "ORDER BY total_tokens DESC\n",
    "\"\"\"\n",
    "\n",
    "cost_estimation = run_query(cost_estimation_sql)\n",
    "cost_estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 3: Error Analysis & Debugging\n",
    "\n",
    "Identify and analyze errors to improve agent reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Error Summary\n",
    "\n",
    "Overview of errors by type and agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "error_summary_sql = f\"\"\"\nSELECT \n    agent,\n    event_type,\n    COUNT(*) as error_count,\n    MIN(timestamp) as first_occurrence,\n    MAX(timestamp) as last_occurrence\nFROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`\nWHERE status = 'ERROR'\n  AND DATE(timestamp) >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)\nGROUP BY agent, event_type\nORDER BY error_count DESC\n\"\"\"\n\nerror_summary = run_query(error_summary_sql)\nif len(error_summary) > 0:\n    print(f\"Found {len(error_summary)} error types:\")\n    display(error_summary)\nelse:\n    print(\"No errors found in the last 7 days!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Error Details\n",
    "\n",
    "Detailed view of recent errors with context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "error_details_sql = f\"\"\"\nSELECT \n    timestamp,\n    agent,\n    session_id,\n    event_type,\n    JSON_EXTRACT_SCALAR(attributes, '$.tool_name') as tool_name,\n    SUBSTR(TO_JSON_STRING(content), 1, 200) as content_preview\nFROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`\nWHERE status = 'ERROR'\n  AND DATE(timestamp) = CURRENT_DATE()\nORDER BY timestamp DESC\nLIMIT 10\n\"\"\"\n\nerror_details = run_query(error_details_sql)\nif len(error_details) > 0:\n    display(error_details)\nelse:\n    print(\"No errors today!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 4: Session & Conversation Analysis\n",
    "\n",
    "Reconstruct and analyze complete agent conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Session Timeline\n",
    "\n",
    "View the complete event timeline for a specific session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, get a sample session ID\n",
    "sample_session_sql = f\"\"\"\n",
    "SELECT DISTINCT session_id\n",
    "FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`\n",
    "WHERE DATE(timestamp) = CURRENT_DATE()\n",
    "  AND session_id IS NOT NULL\n",
    "ORDER BY session_id DESC\n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "\n",
    "sample_session = run_query(sample_session_sql)\n",
    "if len(sample_session) > 0:\n",
    "    session_id = sample_session.iloc[0]['session_id']\n",
    "    print(f\"Analyzing session: {session_id}\")\n",
    "else:\n",
    "    session_id = None\n",
    "    print(\"No sessions found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if session_id:\n",
    "    session_timeline_sql = f\"\"\"\n",
    "    SELECT \n",
    "        timestamp,\n",
    "        event_type,\n",
    "        JSON_EXTRACT_SCALAR(attributes, '$.tool_name') as tool_name,\n",
    "        CAST(JSON_EXTRACT_SCALAR(latency_ms, '$.total_ms') AS INT64) as latency_ms,\n",
    "        status,\n",
    "        SUBSTR(TO_JSON_STRING(content), 1, 200) as content_preview\n",
    "    FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`\n",
    "    WHERE session_id = '{session_id}'\n",
    "    ORDER BY timestamp\n",
    "    \"\"\"\n",
    "    \n",
    "    session_timeline = run_query(session_timeline_sql)\n",
    "    print(f\"Session {session_id} - {len(session_timeline)} events:\")\n",
    "    display(session_timeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Conversation Reconstruction\n",
    "\n",
    "Reconstruct the human-agent conversation from a session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if session_id:\n",
    "    conversation_sql = f\"\"\"\n",
    "    SELECT \n",
    "        timestamp,\n",
    "        CASE \n",
    "            WHEN event_type = 'LLM_REQUEST' THEN 'ðŸ‘¤ User'\n",
    "            WHEN event_type = 'LLM_RESPONSE' THEN 'ðŸ¤– Agent'\n",
    "            WHEN event_type = 'TOOL_STARTING' THEN 'ðŸ”§ Tool Call'\n",
    "            WHEN event_type = 'TOOL_COMPLETED' THEN 'âœ… Tool Result'\n",
    "            ELSE event_type\n",
    "        END as role,\n",
    "        JSON_EXTRACT_SCALAR(attributes, '$.tool_name') as tool,\n",
    "        SUBSTR(JSON_EXTRACT_SCALAR(content, '$.summary'), 1, 300) as message\n",
    "    FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`\n",
    "    WHERE session_id = '{session_id}'\n",
    "      AND event_type IN ('LLM_REQUEST', 'LLM_RESPONSE', 'TOOL_STARTING', 'TOOL_COMPLETED')\n",
    "    ORDER BY timestamp\n",
    "    \"\"\"\n",
    "    \n",
    "    conversation = run_query(conversation_sql)\n",
    "    print(f\"Conversation for session {session_id}:\")\n",
    "    for _, row in conversation.iterrows():\n",
    "        tool_info = f\" [{row['tool']}]\" if pd.notna(row['tool']) else \"\"\n",
    "        print(f\"{row['role']}{tool_info}: {row['message'] or '(no content)'}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 5: User Analytics\n",
    "\n",
    "Understand user behavior and engagement patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 User Engagement Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_engagement_sql = f\"\"\"\n",
    "SELECT \n",
    "    user_id,\n",
    "    COUNT(DISTINCT session_id) as total_sessions,\n",
    "    COUNT(DISTINCT agent) as agents_used,\n",
    "    COUNTIF(event_type = 'LLM_REQUEST') as total_queries,\n",
    "    COUNTIF(event_type = 'TOOL_STARTING') as tool_interactions,\n",
    "    ROUND(AVG(CAST(JSON_EXTRACT_SCALAR(latency_ms, '$.total_ms') AS FLOAT64)), 0) as avg_response_time_ms,\n",
    "    COUNTIF(status = 'ERROR') as errors_encountered\n",
    "FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`\n",
    "WHERE DATE(timestamp) = CURRENT_DATE()\n",
    "  AND user_id IS NOT NULL\n",
    "GROUP BY user_id\n",
    "ORDER BY total_sessions DESC\n",
    "\"\"\"\n",
    "\n",
    "user_engagement = run_query(user_engagement_sql)\n",
    "user_engagement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Agent Preference by User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "user_agent_preference_sql = f\"\"\"\nSELECT \n    user_id,\n    agent,\n    COUNT(DISTINCT session_id) as sessions,\n    COUNT(*) as total_events\nFROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`\nWHERE DATE(timestamp) = CURRENT_DATE()\n  AND user_id IS NOT NULL\n  AND agent IS NOT NULL\nGROUP BY user_id, agent\nORDER BY user_id, sessions DESC\n\"\"\"\n\nuser_agent_pref = run_query(user_agent_preference_sql)\n\nif len(user_agent_pref) > 0 and user_agent_pref['user_id'].notna().any() and user_agent_pref['agent'].notna().any():\n    pivot = user_agent_pref.pivot_table(\n        index='user_id', \n        columns='agent', \n        values='sessions', \n        fill_value=0\n    )\n    \n    if pivot.size > 0 and not pivot.empty:\n        fig, ax = plt.subplots(figsize=(10, 6))\n        pivot.plot(kind='bar', ax=ax)\n        ax.set_title('Agent Usage by User')\n        ax.set_xlabel('User')\n        ax.set_ylabel('Sessions')\n        plt.legend(title='Agent')\n        plt.tight_layout()\n        plt.show()\n    else:\n        print(\"No user-agent preference data available for visualization.\")\nelse:\n    print(\"No user-agent preference data found for today.\")\n\nuser_agent_pref"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 6: Time-Series Analysis\n",
    "\n",
    "Analyze trends over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Hourly Activity Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "hourly_activity_sql = f\"\"\"\nSELECT \n    EXTRACT(HOUR FROM timestamp) as hour,\n    agent,\n    COUNT(*) as event_count\nFROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`\nWHERE DATE(timestamp) = CURRENT_DATE()\n  AND agent IS NOT NULL\nGROUP BY hour, agent\nORDER BY hour, agent\n\"\"\"\n\nhourly_activity = run_query(hourly_activity_sql)\n\nif len(hourly_activity) > 0 and hourly_activity['hour'].notna().any() and hourly_activity['agent'].notna().any():\n    pivot = hourly_activity.pivot_table(\n        index='hour', \n        columns='agent', \n        values='event_count', \n        fill_value=0\n    )\n    \n    if pivot.size > 0 and not pivot.empty:\n        fig, ax = plt.subplots(figsize=(12, 6))\n        pivot.plot(kind='line', marker='o', ax=ax)\n        ax.set_title('Hourly Activity by Agent')\n        ax.set_xlabel('Hour of Day')\n        ax.set_ylabel('Event Count')\n        ax.set_xticks(range(24))\n        plt.legend(title='Agent')\n        plt.tight_layout()\n        plt.show()\n    else:\n        print(\"No hourly activity data available for visualization.\")\nelse:\n    print(\"No hourly activity data found for today.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Latency Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "latency_trend_sql = f\"\"\"\nSELECT \n    TIMESTAMP_TRUNC(timestamp, HOUR) as hour,\n    AVG(CAST(JSON_EXTRACT_SCALAR(latency_ms, '$.total_ms') AS FLOAT64)) as avg_latency_ms,\n    APPROX_QUANTILES(CAST(JSON_EXTRACT_SCALAR(latency_ms, '$.total_ms') AS FLOAT64), 100)[OFFSET(95)] as p95_latency_ms\nFROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`\nWHERE DATE(timestamp) = CURRENT_DATE()\n  AND event_type = 'LLM_RESPONSE'\n  AND JSON_EXTRACT_SCALAR(latency_ms, '$.total_ms') IS NOT NULL\nGROUP BY hour\nORDER BY hour\n\"\"\"\n\nlatency_trend = run_query(latency_trend_sql)\n\nif len(latency_trend) > 0 and latency_trend['hour'].notna().any():\n    fig, ax = plt.subplots(figsize=(12, 6))\n    ax.plot(latency_trend['hour'], latency_trend['avg_latency_ms'], 'b-o', label='Avg Latency')\n    ax.plot(latency_trend['hour'], latency_trend['p95_latency_ms'], 'r--o', label='P95 Latency')\n    ax.set_title('LLM Response Latency Trend')\n    ax.set_xlabel('Time')\n    ax.set_ylabel('Latency (ms)')\n    ax.legend()\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"No latency trend data found for today.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary Dashboard\n",
    "\n",
    "Key metrics at a glance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_sql = f\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) as total_events,\n",
    "    COUNT(DISTINCT session_id) as total_sessions,\n",
    "    COUNT(DISTINCT user_id) as unique_users,\n",
    "    COUNT(DISTINCT agent) as active_agents,\n",
    "    COUNTIF(event_type = 'LLM_REQUEST') as llm_requests,\n",
    "    COUNTIF(event_type = 'TOOL_STARTING') as tool_invocations,\n",
    "    COUNTIF(status = 'ERROR') as total_errors,\n",
    "    ROUND(COUNTIF(status = 'ERROR') * 100.0 / COUNT(*), 2) as error_rate_pct,\n",
    "    ROUND(AVG(CASE WHEN event_type = 'LLM_RESPONSE' \n",
    "        THEN CAST(JSON_EXTRACT_SCALAR(latency_ms, '$.total_ms') AS FLOAT64) END), 0) as avg_llm_latency_ms\n",
    "FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`\n",
    "WHERE DATE(timestamp) = CURRENT_DATE()\n",
    "\"\"\"\n",
    "\n",
    "summary = run_query(summary_sql)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ðŸ“Š LangGraph Agent Analytics - Daily Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nðŸ“ˆ Volume Metrics:\")\n",
    "print(f\"   Total Events:      {summary.iloc[0]['total_events']:,}\")\n",
    "print(f\"   Total Sessions:    {summary.iloc[0]['total_sessions']:,}\")\n",
    "print(f\"   Unique Users:      {summary.iloc[0]['unique_users']:,}\")\n",
    "print(f\"   Active Agents:     {summary.iloc[0]['active_agents']}\")\n",
    "print(f\"\\nðŸ¤– Agent Activity:\")\n",
    "print(f\"   LLM Requests:      {summary.iloc[0]['llm_requests']:,}\")\n",
    "print(f\"   Tool Invocations:  {summary.iloc[0]['tool_invocations']:,}\")\n",
    "print(f\"\\nâš¡ Performance:\")\n",
    "print(f\"   Avg LLM Latency:   {summary.iloc[0]['avg_llm_latency_ms']:,.0f} ms\")\n",
    "print(f\"\\nâŒ Reliability:\")\n",
    "print(f\"   Total Errors:      {summary.iloc[0]['total_errors']:,}\")\n",
    "print(f\"   Error Rate:        {summary.iloc[0]['error_rate_pct']:.2f}%\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "1. **Set up scheduled queries** to run these analytics automatically\n",
    "2. **Create Looker dashboards** for real-time monitoring\n",
    "3. **Configure alerts** for error rate spikes or latency degradation\n",
    "4. **Enable BQML** for advanced analytics (embeddings, sentiment analysis)\n",
    "\n",
    "### Useful SQL Patterns\n",
    "\n",
    "```sql\n",
    "-- Get conversation context for a session\n",
    "SELECT * FROM `project.dataset.agent_events_v2`\n",
    "WHERE session_id = 'your-session-id'\n",
    "ORDER BY timestamp;\n",
    "\n",
    "-- Find slow LLM calls\n",
    "SELECT * FROM `project.dataset.agent_events_v2`\n",
    "WHERE event_type = 'LLM_RESPONSE'\n",
    "  AND CAST(JSON_EXTRACT_SCALAR(latency_ms, '$.total_ms') AS INT64) > 5000;\n",
    "\n",
    "-- Tool success rate\n",
    "SELECT \n",
    "    JSON_EXTRACT_SCALAR(attributes, '$.tool_name') as tool,\n",
    "    COUNTIF(status = 'OK') * 100.0 / COUNT(*) as success_rate\n",
    "FROM `project.dataset.agent_events_v2`\n",
    "WHERE event_type = 'TOOL_COMPLETED'\n",
    "GROUP BY tool;\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}